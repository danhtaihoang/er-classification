{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.metrics import accuracy_score,roc_curve,auc,precision_score,recall_score\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#from expectation_reflection import ExpectationReflection\n",
    "\n",
    "import expectation_reflection_cv as ERCV\n",
    "#import expectation_reflection_cvmc as ERCVMC\n",
    "from function import split_train_test,make_data_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(X_train,y_train,X_test,y_test):     \n",
    "    n = X_train.shape[1]\n",
    "    m = len(np.unique(y_train))\n",
    "\n",
    "    l2 = np.logspace(-5,1,20,base=10.0)\n",
    "    #l2 = [0.,0.00001,0.0001,0.001,0.01,0.1,1.]\n",
    "    nl2 = len(l2)\n",
    "              \n",
    "    kf = 3   \n",
    "    kfold = KFold(n_splits=kf,shuffle=False,random_state=1)\n",
    "\n",
    "    # predict with ER\n",
    "    #if m == 2:\n",
    "    h01 = np.zeros(kf)\n",
    "    w1 = np.zeros((kf,n))\n",
    "    acc1 = np.zeros(kf)\n",
    "    \n",
    "    h0 = np.zeros(nl2)\n",
    "    w = np.zeros((nl2,n))\n",
    "    acc = np.zeros(nl2)            \n",
    "    for il2 in range(nl2):            \n",
    "        for i,(train_index,val_index) in enumerate(kfold.split(y_train)):\n",
    "            X_train1, X_val = X_train[train_index], X_train[val_index]\n",
    "            y_train1, y_val = y_train[train_index], y_train[val_index]\n",
    "            h01[i],w1[i,:] = ERCV.fit(X_train1,y_train1,X_val,y_val,niter_max=1000,l2=l2[il2])\n",
    "            \n",
    "            y_val_pred,p_val_pred = ERCV.predict(X_val,h01[i],w1[i])\n",
    "            #acc1[i] = accuracy_score(y_val,y_val_pred)\n",
    "            acc1[i] = ((p_val_pred - y_val)**2).mean()\n",
    "                                        \n",
    "        h0[il2] = h01.mean(axis=0)\n",
    "        w[il2,:] = w1.mean(axis=0)\n",
    "        acc[il2] = acc1.mean()\n",
    "    \n",
    "    il2_select = np.argmin(acc)\n",
    "    #print('l2:',l2[il2_select])\n",
    "    y_pred,p_pred = ERCV.predict(X_test,h0[il2_select],w[il2_select,:])\n",
    "\n",
    "    # entire training set:\n",
    "    #model = ExpectationReflection(niter_max=1000,l2=l2[il2_select])\n",
    "    #model.fit(X_train,y_train)\n",
    "    #y_pred = model.predict(X_test)\n",
    "                                        \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    cost = ((p_pred - y_test)**2).mean()\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "  \n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr, tpr,thresholds = roc_curve(y_test, p_pred, drop_intermediate=False)\n",
    "    roc_auc= auc(fpr, tpr)\n",
    "\n",
    "    #print(len(p_pred),len(y_test),len(fpr),len(tpr))                       \n",
    "\n",
    "    return accuracy,roc_auc,precision,recall,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_inference(X,y,train_size):\n",
    "    npred = 5\n",
    "    acc = np.zeros(npred)\n",
    "    roc_auc = np.zeros(npred)\n",
    "    precision = np.zeros(npred)\n",
    "    recall = np.zeros(npred)\n",
    "    cost = np.zeros(npred)\n",
    "    for ipred in range(npred):\n",
    "        X_train,X_test,y_train,y_test = split_train_test(X,y,train_size,test_size=0.7)\n",
    "\n",
    "        #X_train = MinMaxScaler().fit_transform(X_train)\n",
    "        #X_test = MinMaxScaler().fit_transform(X_test)\n",
    "        \n",
    "        # 2019.07.15\n",
    "        #acc[ipred],cost[ipred],roc_auc[ipred] = inference(X_train,y_train,X_test,y_test)\n",
    "        acc[ipred],roc_auc[ipred],precision[ipred],recall[ipred],cost[ipred] \\\n",
    "        = inference(X_train,y_train,X_test,y_test)\n",
    "            \n",
    "    #return acc.mean(axis=0),acc.std(),cost.mean(),cost.std(),roc_auc.mean(),roc_auc.std()\n",
    "    return acc.mean(axis=0),roc_auc.mean(),precision.mean(),recall.mean(),cost.mean(),\\\n",
    "           acc.std(),roc_auc.std(),precision.std(),recall.std(),cost.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3 [0.71132075 0.79480242 0.71441925 0.73207547 0.18906471 0.04202086\n",
      " 0.03536455 0.07002356 0.08128551 0.01777017]\n",
      "0 0.3 [0.9        0.93515625 0.87421495 0.9375     0.07909754 0.06373774\n",
      " 0.01686487 0.0591122  0.09682458 0.02496886]\n",
      "0 0.3 [0.56       0.55644444 0.57571429 0.49333333 0.24931914 0.16918103\n",
      " 0.17092111 0.18633839 0.17178798 0.01506815]\n",
      "0 0.3 [0.95405405 0.98791088 0.96306503 0.94459459 0.03378232 0.00921499\n",
      " 0.00131032 0.01583239 0.00993036 0.00529247]\n",
      "0 0.3 [0.57966102 0.59747199 0.5916911  0.55932203 0.2488208  0.04535284\n",
      " 0.03865189 0.05979884 0.06779661 0.01020951]\n",
      "0 0.3 [0.79428571 0.82881633 0.80209002 0.78857143 0.16892048 0.03331973\n",
      " 0.02330409 0.04872203 0.07362342 0.02632838]\n",
      "0 0.3 [0.88636364 0.94783058 0.93045045 0.84090909 0.08709135 0.02032789\n",
      " 0.01024239 0.05658588 0.04065578 0.01117048]\n",
      "0 0.3 [0.85744681 0.9118153  0.82007904 0.91914894 0.11788684 0.04070452\n",
      " 0.00926154 0.04622514 0.03127008 0.01824963]\n",
      "0 0.3 [0.59339243 0.63742433 0.59081037 0.60741338 0.23721419 0.00811583\n",
      " 0.00842484 0.0071936  0.01611926 0.00318964]\n",
      "0 0.3 [0.99315068 1.         0.98669986 1.         0.00743041 0.00750305\n",
      " 0.         0.0144148  0.         0.00373713]\n",
      "0 0.3 [0.99426877 0.99694809 0.98869367 1.         0.00488534 0.0026069\n",
      " 0.00238908 0.00508745 0.         0.00197   ]\n",
      "0 0.3 [0.61846591 0.67184433 0.61610598 0.63125    0.22932846 0.00699349\n",
      " 0.00963445 0.01156639 0.02661372 0.00379473]\n",
      "0 0.3 [1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 3.06661263e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.10016508e-04]\n",
      "0 0.3 [0.8878327  0.94049647 0.97644672 0.79543726 0.08362551 0.00741201\n",
      " 0.0209753  0.01878009 0.02003337 0.00996287]\n",
      "0 0.3 [0.81956522 0.88969754 0.88160661 0.74347826 0.13230688 0.04101731\n",
      " 0.02116991 0.06550729 0.07327087 0.01227532]\n",
      "0 0.3 [0.51474359 0.52546022 0.51551491 0.48717949 0.25355459 0.01242995\n",
      " 0.0126127  0.01267011 0.03217923 0.00416864]\n",
      "0 0.3 [0.78181818 0.8332211  0.80525013 0.74343434 0.16724877 0.01545157\n",
      " 0.0118101  0.01213693 0.03103493 0.00439908]\n",
      "0 0.3 [0.69166667 0.77037037 0.68275648 0.73888889 0.20652531 0.09145599\n",
      " 0.07930447 0.09537255 0.11194134 0.02483233]\n",
      "0 0.3 [0.84482759 0.90273484 0.85022362 0.84137931 0.12315638 0.05229569\n",
      " 0.05928824 0.06426222 0.05602785 0.04551378]\n",
      "0 0.3 [0.60869565 0.63884688 0.64355311 0.5173913  0.24095716 0.02280019\n",
      " 0.02636212 0.05751574 0.10233567 0.00308432]\n",
      "0 0.3 [0.65681818 0.70878099 0.65434541 0.68181818 0.23469689 0.01818182\n",
      " 0.00983523 0.03072011 0.10464422 0.01601792]\n",
      "0 0.3 [0.81875    0.89969618 0.7912856  0.875      0.13827033 0.02517301\n",
      " 0.02933652 0.05191663 0.02946278 0.02245312]\n",
      "0 0.3 [0.66810345 0.73492866 0.71509798 0.56206897 0.20555707 0.0196582\n",
      " 0.01928163 0.03242581 0.04442793 0.00696776]\n",
      "0 0.3 [0.74462366 0.80950399 0.73470951 0.76774194 0.17991762 0.01272275\n",
      " 0.01869016 0.01968787 0.02553622 0.00927398]\n"
     ]
    }
   ],
   "source": [
    "data_name_list = ['nki','peptide','amputation','wisconsin','heat','hc','paradox','school','stigma','ef',\\\n",
    "                 'smok','coag','anemia','cervix','mental','dement','septic','coimbra','cryo','somerville',\\\n",
    "                  'hcc','heart','liver','language']\n",
    "n_data = len(data_name_list)\n",
    "\n",
    "for data_id in range(n_data):\n",
    "    data_name = data_name_list[data_id]\n",
    "    # load data\n",
    "    X = np.loadtxt('data_sets/%s_x.txt'%data_name)\n",
    "    y = np.loadtxt('data_sets/%s_y.txt'%data_name)\n",
    "    #print('ini:',np.unique(y,return_counts=True))\n",
    "\n",
    "    X,y = make_data_balance(X,y)\n",
    "    #print('balance:',np.unique(y,return_counts=True))\n",
    "\n",
    "    X, y = shuffle(X, y)\n",
    "    X = MinMaxScaler().fit_transform(X)                  \n",
    "\n",
    "    list_train_size = [0.3]\n",
    "    n_size = len(list_train_size)\n",
    "    acc = np.zeros((n_size,10)) # 0: acc, 1: acc_std, 2: cost, 3: cost_std\n",
    "    for i,train_size in enumerate(list_train_size):\n",
    "        acc[i,:] = compare_inference(X,y,train_size)\n",
    "        print(i,train_size,acc[i,:])\n",
    "\n",
    "    np.savetxt('result/%s_acc.dat'%data_name,acc,fmt='%f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
